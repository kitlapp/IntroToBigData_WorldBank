{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad1186e0-ccd5-4399-85ea-9363aa0764a1",
   "metadata": {},
   "source": [
    "# ANALYZING GLOBAL HEALTH AND ENVIRONMENTAL TRENDS USING WORLD BANK DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab735e94-c157-4822-9d55-45b54565b2a5",
   "metadata": {},
   "source": [
    "# A Data-Driven Study with MySQL Database Integration and Python Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb84260-102b-473e-8c24-fe0ab3ae6e6e",
   "metadata": {},
   "source": [
    "---\n",
    "### We greatly acknowledge the World Bank Group for the collection and sharing of the data.\n",
    "---\n",
    "\n",
    "The indicator descriptions below are based on the metadata provided with each dataset. For ‘Total Greenhouse Gas Emissions Including LULUCF (Mt CO2e),’ no metadata was available, so we conducted a brief research to understand it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec3261c-e711-48a1-b883-c87a745db06f",
   "metadata": {},
   "source": [
    "## Health Indicators Description"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "32095d90-a5cb-46bb-8af6-6043237db1df",
   "metadata": {},
   "source": [
    "**1. Current Health Expenditure (% of GDP)**  \n",
    "This indicator shows how much a country spends on health care compared to its total economic output (GDP). It includes the health services and goods that are used within the year. It does not cover long-term investments such as buildings, medical equipment, IT systems, or vaccine stockpiles for emergencies.\n",
    "\n",
    "**2. People Using at Least Basic Drinking Water Services, Rural (% of Rural Population)**  \n",
    "This indicator shows the share of rural residents who have access to at least basic drinking water services. It includes both basic and safely managed water services. Basic services refer to drinking water from an improved source, as long as the total round-trip collection time is under 30 minutes. Improved sources include piped water, boreholes, protected wells or springs, and packaged or delivered water.\n",
    "\n",
    "**3. People Using at Least Basic Drinking Water Services, Urban (% of Urban Population)**  \n",
    "This indicator shows the share of urban residents who have access to at least basic drinking water services. It includes both basic and safely managed water services. Basic services mean getting water from an improved source, as long as the total time to go there and return is under 30 minutes. Improved sources include piped water, boreholes, protected wells or springs, and packaged or delivered water.\n",
    "\n",
    "**4. People Using Safely Managed Sanitation Services, Rural (% of Rural Population)**  \n",
    "This indicator shows the share of rural residents who use improved sanitation facilities that are not shared with other households. It includes systems where waste is safely managed on-site or collected and treated offsite. Improved sanitation facilities include flush or pour-flush toilets connected to sewers, septic tanks or pit latrines, as well as ventilated improved pit latrines, composting toilets, and pit latrines with a slab.\n",
    "\n",
    "**5. People Using Safely Managed Sanitation Services, Urban (% of Urban Population)**  \n",
    "This indicator shows the share of urban residents who use improved sanitation facilities that are not shared with other households. It includes systems where waste is safely managed on-site or collected and treated offsite. Improved sanitation facilities include flush or pour-flush toilets connected to sewers, septic tanks or pit latrines, as well as ventilated improved pit latrines, composting toilets, and pit latrines with a slab."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a379c067-61f2-42f5-99e5-f6dcc52b5f32",
   "metadata": {},
   "source": [
    "## Environment Indicators Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231ede2b-bc58-4105-9e01-064bcfd857ee",
   "metadata": {},
   "source": [
    "**6. Total Greenhouse Gas Emissions Including LULUCF (Mt CO2e)**  \n",
    "This indicator measures the total greenhouse gas emissions of a country, including the effects of land use, land-use changes, and forestry (LULUCF), expressed in million tonnes of CO₂ equivalent. LULUCF accounts for carbon released or absorbed due to changes in land cover, such as deforestation, afforestation, or forest management. This gives a complete view of a country’s contribution to climate change.\n",
    "\n",
    "**7. Population, Total**  \n",
    "This indicator reports the total number of people living in a country, based on the de facto population concept. It counts all residents, no matter their legal status or citizenship. The figures represent estimates taken around the middle of each year.\n",
    "\n",
    "**8. Renewable Energy Consumption (% of Total Final Energy Consumption)**  \n",
    "This indicator shows the percentage of a country’s total final energy use that comes from renewable sources. It reflects how much of the energy consumed is produced from renewables instead of fossil fuels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16d97d2c-6d10-48d4-8b3e-881708699f14",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Adespotos\\\\anaconda3\\\\envs\\\\bigdata_env\\\\python.exe'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that jupyter lab points to your project's environment directory\n",
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69be70bf-1b04-43dc-a384-fa54dec40ea1",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe5b17b7-1263-432d-97a7-77d354fe98d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # Numerical computing library\n",
    "import pandas as pd  # Data handling\n",
    "import matplotlib.pyplot as plt  # Plotting library\n",
    "import seaborn as sns  # An updated matplotlib (for better visualizations)\n",
    "import pymysql  # MySQL database connector for Python\n",
    "import chardet  # Library for automatic character encoding detection\n",
    "import re  # Regular expressions for string manipulation and pattern matching\n",
    "\n",
    "import custom_functions  # Custom functions for this project (e.g., CSV cleaning, encoding detection)\n",
    "\n",
    "pd.options.display.max_columns = 100  # Display all columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c6ff14-85b8-467d-b7fe-40fbfb144309",
   "metadata": {},
   "source": [
    "# DATA HARVESTING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef6adff-4d96-42e1-8c4e-e649c40c557b",
   "metadata": {},
   "source": [
    "# Read Datasets to DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d9a10a-ea74-40a6-b5e9-f7d211695f85",
   "metadata": {},
   "source": [
    "A detailed exploration of the CSV files is necessary to ensure they can be read correctly into DataFrames.\n",
    "\n",
    "We selected five health indicators and three environmental indicators. Some of these files are too complex to be read directly into DataFrames. The complexity became apparent when we realized that pandas.read_csv() could not handle the files properly, producing unreliable results.\n",
    "\n",
    "Rather than choosing easier files, we took this as an opportunity to develop a step-by-step solution and learn as much as possible from the process. The Pythonic approach we followed includes the steps below:\n",
    "\n",
    "1. Ensure the correct file encoding.\n",
    "2. Fetch the CSV files into Python’s runtime (without using pandas, since it could not read the files correctly).\n",
    "3. Explore the fetched CSV content to identify the issues.\n",
    "4. Write scripts to address one problem at a time, progressing toward the final solution.\n",
    "\n",
    "The indicators that required this special treatment were **\"Population, total\"** and **\"Renewable energy consumption (% of total final energy consumption)\"**. For this reason, we separated these two files from the rest, assigning them the notation 2, while the remaining files use the notation 1.\n",
    "\n",
    "To handle the process described above, we also created three custom functions for reading and cleaning the CSV files. We also included docstrings in our functions to improve their readability and understanding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36e5099-9da5-48ab-9e0a-27dbca7dbcf8",
   "metadata": {},
   "source": [
    "Therefore, as the first preprocessing step, we create the lists with file paths and data abbreviations. The mechanics are simple: the first element of filepaths_1 corresponds to the first element of abbreviations_1. The same applies to filepaths_2 and abbreviations_2. So, the custom creation order of the list elements matters. These lists make automation easier and help map each file to its abbreviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "756ef0e9-dd7e-4e16-8a3e-533ad1582d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths for notation 1 ('che', 'wr', 'wu', 'sr', 'su', 'gem')\n",
    "filepaths_1 = ['UPDATED CSV DATA - Intro to Big Data/Current health expenditure (% of GDP).csv',\n",
    "               'UPDATED CSV DATA - Intro to Big Data/People using at least basic drinking water services, rural (% of rural population).csv',\n",
    "               'UPDATED CSV DATA - Intro to Big Data/People using at least basic drinking water services, urban (% of urban population).csv',\n",
    "               'UPDATED CSV DATA - Intro to Big Data/People using safely managed sanitation services, rural (% of rural population).csv',\n",
    "               'UPDATED CSV DATA - Intro to Big Data/People using safely managed sanitation services, urban (% of urban population).csv',\n",
    "               'UPDATED CSV DATA - Intro to Big Data/Total greenhouse gas emissions including LULUCF (Mt CO2e).csv']\n",
    "\n",
    "# File paths for notation 2 ('pop', 'ren')\n",
    "filepaths_2 = ['UPDATED CSV DATA - Intro to Big Data/Population, total.csv',\n",
    "               'UPDATED CSV DATA - Intro to Big Data/Renewable energy consumption (% of total final energy consumption).csv']\n",
    "\n",
    "# Abbreviations for easy mapping: notation 1\n",
    "abbreviations_1 = ['che', 'wr', 'wu', 'sr', 'su', 'gem']\n",
    "\n",
    "# Abbreviations for easy mapping: notation 2\n",
    "abbreviations_2 = ['pop', 'ren']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e915cf-952a-4e18-b87e-755c7c1a4ac0",
   "metadata": {},
   "source": [
    "### Step 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41afcad-98f7-452d-a0d1-bbc84f862b9d",
   "metadata": {},
   "source": [
    "We use a function, leveraging chardet library's capabilities, to detect the file encoding, ensuring that no encoding issues occur when opening the CSV files in Python, which could otherwise disrupt our approach. We automated the process by iterating simultaneously over the abbreviations and filepaths lists. This type of iteration ensures that when Python processes element 0 of abbreviations, it also processes element 0 of filepaths, so each abbreviation corresponds to the correct file path."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0266c6d-5561-4634-b19b-52b4d2d245ef",
   "metadata": {},
   "source": [
    "**Notation 1 Files:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd70997e-ec74-451c-89e1-544862a20d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the files' encodings: \n",
      " {'che': 'UTF-8-SIG', 'wr': 'UTF-8-SIG', 'wu': 'UTF-8-SIG', 'sr': 'UTF-8-SIG', 'su': 'UTF-8-SIG', 'gem': 'UTF-8-SIG'}\n"
     ]
    }
   ],
   "source": [
    "# Dictionary to store detected encodings for each CSV file\n",
    "encodings_1 = {}\n",
    "\n",
    "# Iterate through abbreviations and filepaths together, detect encoding for each file\n",
    "for abbreviation, filepath in zip(abbreviations_1, filepaths_1):\n",
    "    encodings_1[abbreviation] = custom_functions.detect_encoding(filepath)\n",
    "\n",
    "# Print the results to verify encodings\n",
    "print(\"Here are the files' encodings: \\n\", encodings_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4210b0-b85b-4050-9f49-378331d30bb7",
   "metadata": {},
   "source": [
    "**Notation 2 Files:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42858863-c5ab-497b-a4f1-3214a528fb9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the files' encodings: \n",
      " {'pop': 'UTF-8-SIG', 'ren': 'UTF-8-SIG'}\n"
     ]
    }
   ],
   "source": [
    "# Dictionary to store detected encodings for each CSV file\n",
    "encodings_2 = {}\n",
    "\n",
    "# Iterate through abbreviations and filepaths together, detect encoding for each file\n",
    "for abbreviation, filepath in zip(abbreviations_2, filepaths_2):\n",
    "    encodings_2[abbreviation] = custom_functions.detect_encoding(filepath)\n",
    "\n",
    "# Print the results to verify encodings\n",
    "print(\"Here are the files' encodings: \\n\", encodings_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535a1f98-0434-48c3-8b7c-09f1eaeb0292",
   "metadata": {},
   "source": [
    "At this point, all encodings are safely stored as values in a dictionary. Things seem simple because the encodings are currently the same. However, if they ever differ, each encoding can be accessed using the corresponding dictionary key. Even though the situation looks straightforward now, we follow a dynamic approach and retrieve the encodings through the dictionary keys instead of writing the encoding manually for each file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb99f19f-9cd0-485d-9306-0dbe091f7b75",
   "metadata": {},
   "source": [
    "### Step 2 & 3:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2204ab-eebd-4557-a313-197e83b6c804",
   "metadata": {},
   "source": [
    "Since Pandas cannot handle reading these CSV files directly, we can use standard Python to load portions of a CSV file into memory. We can automate this process as before by iterating through both the filepaths and abbreviations lists and using a custom function that returns a selected line from each CSV file. We also use the repr() function, which is very helpful in situations like this, since the print() function often alters the displayed content. It is important to load the original CSV lines into memory without any changes to correctly identify the necessary actions to clean the files so that Pandas can read them successfully."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6ad6b9-70e2-4d05-a789-2de7a7e2996b",
   "metadata": {},
   "source": [
    "**Notation 1 Files:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35485635-b998-4b91-903b-759bed311bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "che:\n",
      "'Country Name;Country Code;Indicator Name;Indicator Code;1960;1961;1962;1963;1964;1965;1966;1967;1968;1969;1970;1971;1972;1973;1974;1975;1976;1977;1978;1979;1980;1981;1982;1983;1984;1985;1986;1987;1988;1989;1990;1991;1992;1993;1994;1995;1996;1997;1998;1999;2000;2001;2002;2003;2004;2005;2006;2007;2008;2009;2010;2011;2012;2013;2014;2015;2016;2017;2018;2019;2020;2021;2022;2023;2024\\n'\n",
      "wr:\n",
      "'Country Name;Country Code;Indicator Name;Indicator Code;1960;1961;1962;1963;1964;1965;1966;1967;1968;1969;1970;1971;1972;1973;1974;1975;1976;1977;1978;1979;1980;1981;1982;1983;1984;1985;1986;1987;1988;1989;1990;1991;1992;1993;1994;1995;1996;1997;1998;1999;2000;2001;2002;2003;2004;2005;2006;2007;2008;2009;2010;2011;2012;2013;2014;2015;2016;2017;2018;2019;2020;2021;2022;2023;2024\\n'\n",
      "wu:\n",
      "'Country Name;Country Code;Indicator Name;Indicator Code;1960;1961;1962;1963;1964;1965;1966;1967;1968;1969;1970;1971;1972;1973;1974;1975;1976;1977;1978;1979;1980;1981;1982;1983;1984;1985;1986;1987;1988;1989;1990;1991;1992;1993;1994;1995;1996;1997;1998;1999;2000;2001;2002;2003;2004;2005;2006;2007;2008;2009;2010;2011;2012;2013;2014;2015;2016;2017;2018;2019;2020;2021;2022;2023;2024\\n'\n",
      "sr:\n",
      "'Country Name;Country Code;Indicator Name;Indicator Code;1960;1961;1962;1963;1964;1965;1966;1967;1968;1969;1970;1971;1972;1973;1974;1975;1976;1977;1978;1979;1980;1981;1982;1983;1984;1985;1986;1987;1988;1989;1990;1991;1992;1993;1994;1995;1996;1997;1998;1999;2000;2001;2002;2003;2004;2005;2006;2007;2008;2009;2010;2011;2012;2013;2014;2015;2016;2017;2018;2019;2020;2021;2022;2023;2024\\n'\n",
      "su:\n",
      "'Country Name;Country Code;Indicator Name;Indicator Code;1960;1961;1962;1963;1964;1965;1966;1967;1968;1969;1970;1971;1972;1973;1974;1975;1976;1977;1978;1979;1980;1981;1982;1983;1984;1985;1986;1987;1988;1989;1990;1991;1992;1993;1994;1995;1996;1997;1998;1999;2000;2001;2002;2003;2004;2005;2006;2007;2008;2009;2010;2011;2012;2013;2014;2015;2016;2017;2018;2019;2020;2021;2022;2023;2024\\n'\n",
      "gem:\n",
      "'Country Name;Country Code;Indicator Name;Indicator Code;1960;1961;1962;1963;1964;1965;1966;1967;1968;1969;1970;1971;1972;1973;1974;1975;1976;1977;1978;1979;1980;1981;1982;1983;1984;1985;1986;1987;1988;1989;1990;1991;1992;1993;1994;1995;1996;1997;1998;1999;2000;2001;2002;2003;2004;2005;2006;2007;2008;2009;2010;2011;2012;2013;2014;2015;2016;2017;2018;2019;2020;2021;2022;2023;2024\\n'\n"
     ]
    }
   ],
   "source": [
    "# Iterate through abbreviations and filepaths together, print a CSV line for each file\n",
    "for abbreviation, filepath in zip(abbreviations_1, filepaths_1):\n",
    "    csv_part = custom_functions.explore_csv(filepath=filepath, encoding=encodings_1[abbreviation], line_number=3)\n",
    "    print(abbreviation + \":\")\n",
    "    print(repr(csv_part))  # repr() displays the string exactly as it is, unlike print() which might ruin special characters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ffcc3f-b9d5-4b7c-9338-1e70f8977399",
   "metadata": {},
   "source": [
    "**Notation 2 Files:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e851655b-a918-41c8-8b05-7aee8799b54e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pop:\n",
      "'\"Country Name,\"\"Country Code\"\",\"\"Indicator Name\"\",\"\"Indicator Code\"\",\"\"1960\"\",\"\"1961\"\",\"\"1962\"\",\"\"1963\"\",\"\"1964\"\",\"\"1965\"\",\"\"1966\"\",\"\"1967\"\",\"\"1968\"\",\"\"1969\"\",\"\"1970\"\",\"\"1971\"\",\"\"1972\"\",\"\"1973\"\",\"\"1974\"\",\"\"1975\"\",\"\"1976\"\",\"\"1977\"\",\"\"1978\"\",\"\"1979\"\",\"\"1980\"\",\"\"1981\"\",\"\"1982\"\",\"\"1983\"\",\"\"1984\"\",\"\"1985\"\",\"\"1986\"\",\"\"1987\"\",\"\"1988\"\",\"\"1989\"\",\"\"1990\"\",\"\"1991\"\",\"\"1992\"\",\"\"1993\"\",\"\"1994\"\",\"\"1995\"\",\"\"1996\"\",\"\"1997\"\",\"\"1998\"\",\"\"1999\"\",\"\"2000\"\",\"\"2001\"\",\"\"2002\"\",\"\"2003\"\",\"\"2004\"\",\"\"2005\"\",\"\"2006\"\",\"\"2007\"\",\"\"2008\"\",\"\"2009\"\",\"\"2010\"\",\"\"2011\"\",\"\"2012\"\",\"\"2013\"\",\"\"2014\"\",\"\"2015\"\",\"\"2016\"\",\"\"2017\"\",\"\"2018\"\",\"\"2019\"\",\"\"2020\"\",\"\"2021\"\",\"\"2022\"\",\"\"2023\"\",\"\"2024\"\",\"\\n'\n",
      "ren:\n",
      "'\"Country Name,\"\"Country Code\"\",\"\"Indicator Name\"\",\"\"Indicator Code\"\",\"\"1960\"\",\"\"1961\"\",\"\"1962\"\",\"\"1963\"\",\"\"1964\"\",\"\"1965\"\",\"\"1966\"\",\"\"1967\"\",\"\"1968\"\",\"\"1969\"\",\"\"1970\"\",\"\"1971\"\",\"\"1972\"\",\"\"1973\"\",\"\"1974\"\",\"\"1975\"\",\"\"1976\"\",\"\"1977\"\",\"\"1978\"\",\"\"1979\"\",\"\"1980\"\",\"\"1981\"\",\"\"1982\"\",\"\"1983\"\",\"\"1984\"\",\"\"1985\"\",\"\"1986\"\",\"\"1987\"\",\"\"1988\"\",\"\"1989\"\",\"\"1990\"\",\"\"1991\"\",\"\"1992\"\",\"\"1993\"\",\"\"1994\"\",\"\"1995\"\",\"\"1996\"\",\"\"1997\"\",\"\"1998\"\",\"\"1999\"\",\"\"2000\"\",\"\"2001\"\",\"\"2002\"\",\"\"2003\"\",\"\"2004\"\",\"\"2005\"\",\"\"2006\"\",\"\"2007\"\",\"\"2008\"\",\"\"2009\"\",\"\"2010\"\",\"\"2011\"\",\"\"2012\"\",\"\"2013\"\",\"\"2014\"\",\"\"2015\"\",\"\"2016\"\",\"\"2017\"\",\"\"2018\"\",\"\"2019\"\",\"\"2020\"\",\"\"2021\"\",\"\"2022\"\",\"\"2023\"\",\"\"2024\"\",\"\\n'\n"
     ]
    }
   ],
   "source": [
    "# Iterate through abbreviations and filepaths together, print a CSV line for each file\n",
    "for abbreviation, filepath in zip(abbreviations_2, filepaths_2):\n",
    "    csv_part = custom_functions.explore_csv(filepath=filepath, encoding=encodings_2[abbreviation], line_number=4)\n",
    "    print(abbreviation + \":\")\n",
    "    print(repr(csv_part))  # repr() displays the string exactly as it is, unlike print() which ruins special characters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95b9fb0-7fee-447f-8da8-8f59176e2b40",
   "metadata": {},
   "source": [
    "The above scripts, along with the custom function explore_csv, helped us identify the following:\n",
    "\n",
    "1. All notation 1 files start at line number 3, whereas notation 2 files start at line number 4. The preceding lines contain metadata at both cases.\n",
    "2. All notation 1 files use ';' as a separator, whereas notation 2 files use ','.\n",
    "3. Rows in every file end with a newline character '\\n'.\n",
    "4. There are empty strings that should be manually converted to NaN values. Otherwise, pandas cannot recognize them as missing data.\n",
    "5. Apart from the delimiter and the newline character at the end, the notation 1 files are clean, while notation 2 files include the following extra issues:  \n",
    "    a. Each row ends with a comma followed by a quote, before the newline character: ',\"\\n'.  \n",
    "    b. Quotes included in the data.  \n",
    "    c. In 'pop', there is an extra comma in the column name 'Population, total', which causes pandas to treat 'Population' and 'total' as separate columns, even though they belong to the same column.  \n",
    "    d. Each list element represents a row of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722778e4-8c07-4fcb-ad76-08006ee5f18e",
   "metadata": {},
   "source": [
    "Although the identification appears to be correct and effective, the order of execution of the above instructions is important. For instance, removing all quotes before applying rstrip() can lead to unreliable results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0114c1e2-3047-4251-80cd-dba76ed849f1",
   "metadata": {},
   "source": [
    "### Step 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e151ce7-7ac0-4c6f-bb0d-b06cb357bb34",
   "metadata": {},
   "source": [
    "We created a custom function to clean all files. The function is dynamic, meaning it can handle both notation 1 and notation 2 datasets. The only point that requires attention is that the function must accept different arguments depending on the file notation. As mentioned before, notation 2 files require special treatment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8544644-922a-4006-b5a9-4e13d1a5bd6c",
   "metadata": {},
   "source": [
    "We adopted a new approach by creating a third list that maps to the other two lists introduced earlier. This third list contains the names of the DataFrames."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaba3b22-6fbe-4608-9f5e-ac963f5af21b",
   "metadata": {},
   "source": [
    "**Reading Notation 1 Files to DataFrames:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cc2b8bb-45f9-4a32-9176-21b05e934b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of the DataFrames for notation 1\n",
    "dfnames_1 = ['df_che', 'df_wr', 'df_wu', 'df_sr', 'df_su', 'df_gem']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bd9df30-0eb0-4054-bc0e-ec1534904844",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict_1 = {}  # Initialize an empty dictionary to store the DataFrames\n",
    "\n",
    "# Iterate through the three lists simultaneously.\n",
    "# This works because the lists were created with the correct mapping order.\n",
    "for df_name, abbreviation, filepath in zip(dfnames_1, abbreviations_1, filepaths_1):\n",
    "    # Use the DataFrame name string as the key in the dictionary\n",
    "    df_dict_1[df_name] = custom_functions.clean_csv(\n",
    "        filepath=filepath,  # Path to the CSV file\n",
    "        encoding=encodings_1[abbreviation],  # Retrieve encoding based on abbreviation\n",
    "        separator=';',   # Set the column delimiter\n",
    "        trail1='\\n',  # First trailing character to remove\n",
    "        trail2=None,  # Second trailing character to remove (optional)\n",
    "        trail3=None,  # Third trailing character to remove (optional)\n",
    "        to_be_replaced='\"',  # Characters to replace (quotes in this case)\n",
    "        start_row=3  # Row index corresponding to column headers\n",
    "    )\n",
    "\n",
    "# Extract the DataFrames from the dictionary and assign to variables\n",
    "df_che = df_dict_1['df_che']\n",
    "df_wr  = df_dict_1['df_wr']\n",
    "df_wu  = df_dict_1['df_wu']\n",
    "df_sr  = df_dict_1['df_sr']\n",
    "df_su  = df_dict_1['df_su']\n",
    "df_gem = df_dict_1['df_gem']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d1cdfc-af08-4a00-9f51-65f87c09794a",
   "metadata": {},
   "source": [
    "**Reading Notation 2 Files to DataFrames:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a382c21c-20f2-464c-b7bf-72e71b0f1db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of the DataFrames for notation 2\n",
    "dfnames_2 = ['df_pop', 'df_ren']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "adc6b8bf-bcf6-47db-83f8-120b75fa96cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict_2 = {}\n",
    "\n",
    "for df_name, abbreviation, filepath in zip(dfnames_2, abbreviations_2, filepaths_2):\n",
    "    df_dict_2[df_name] = custom_functions.clean_csv(\n",
    "        filepath=filepath,\n",
    "        encoding=encodings_2[abbreviation],\n",
    "        separator=',',\n",
    "        trail1='\\n',\n",
    "        trail2='\"',\n",
    "        trail3=',',\n",
    "        to_be_replaced='\"',\n",
    "        start_row=4\n",
    "    )\n",
    "    \n",
    "df_pop = df_dict_2['df_pop']\n",
    "df_ren = df_dict_2['df_ren']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232370bf-ce5d-49a8-8202-99be6ae051a3",
   "metadata": {},
   "source": [
    "# Quick Exploration on Data Integrity & Observations "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6de22d-8ad0-4b6c-aee7-5f6dabbae451",
   "metadata": {},
   "source": [
    "The results appear reliable, as all DataFrames have the same shape and identical column names. A quick inspection suggests that our cleaning process has been effective. All indicators are related to countries, so the 266 rows represent countries and territories worldwide. The 193 sovereign countries are included, but the additional rows correspond to non-independent territories, overseas dependencies and entire regions, such as Puerto Rico, Hong Kong, Bermuda, Africa Eastern and Southern. Arab World etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932f34bd-0781-4dd8-954f-7c9d6348f2aa",
   "metadata": {},
   "source": [
    "The indicators’ data have been collected from 1960 to the present (2024). There are several reasons why 1960 is used as the starting year. By this time, most countries had rebuilt or established functioning statistical offices after World War II, enabling systematic and comparable data collection. Additionally, decolonization and the formation of new countries occurred primarily in the 1950s and 1960s. Many nations became independent around this period, so data prior to 1960 would often be incomplete, inconsistent, or recorded under colonial administrations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "804fd065-d860-4c3b-b19a-1700cf979906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "che: (266, 69)\n",
      "wr: (266, 69)\n",
      "wu: (266, 69)\n",
      "sr: (266, 69)\n",
      "su: (266, 69)\n",
      "pop: (266, 69)\n",
      "ren: (266, 69)\n",
      "gem: (266, 69)\n"
     ]
    }
   ],
   "source": [
    "print('che:', df_che.shape)\n",
    "print('wr:', df_wr.shape)\n",
    "print('wu:', df_wu.shape)\n",
    "print('sr:', df_sr.shape)\n",
    "print('su:', df_su.shape)\n",
    "print('pop:', df_pop.shape)\n",
    "print('ren:', df_ren.shape)\n",
    "print('gem:', df_gem.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8f361ce-26e1-4a0f-a214-6b65554dac2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "che Columns:\n",
      " Index(['Country Name', 'Country Code', 'Indicator Name', 'Indicator Code',\n",
      "       '1960', '1961', '1962', '1963', '1964', '1965', '1966', '1967', '1968',\n",
      "       '1969', '1970', '1971', '1972', '1973', '1974', '1975', '1976', '1977',\n",
      "       '1978', '1979', '1980', '1981', '1982', '1983', '1984', '1985', '1986',\n",
      "       '1987', '1988', '1989', '1990', '1991', '1992', '1993', '1994', '1995',\n",
      "       '1996', '1997', '1998', '1999', '2000', '2001', '2002', '2003', '2004',\n",
      "       '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013',\n",
      "       '2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022',\n",
      "       '2023', '2024'],\n",
      "      dtype='object')\n",
      "wr Columns:\n",
      " Index(['Country Name', 'Country Code', 'Indicator Name', 'Indicator Code',\n",
      "       '1960', '1961', '1962', '1963', '1964', '1965', '1966', '1967', '1968',\n",
      "       '1969', '1970', '1971', '1972', '1973', '1974', '1975', '1976', '1977',\n",
      "       '1978', '1979', '1980', '1981', '1982', '1983', '1984', '1985', '1986',\n",
      "       '1987', '1988', '1989', '1990', '1991', '1992', '1993', '1994', '1995',\n",
      "       '1996', '1997', '1998', '1999', '2000', '2001', '2002', '2003', '2004',\n",
      "       '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013',\n",
      "       '2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022',\n",
      "       '2023', '2024'],\n",
      "      dtype='object')\n",
      "wu Columns:\n",
      " Index(['Country Name', 'Country Code', 'Indicator Name', 'Indicator Code',\n",
      "       '1960', '1961', '1962', '1963', '1964', '1965', '1966', '1967', '1968',\n",
      "       '1969', '1970', '1971', '1972', '1973', '1974', '1975', '1976', '1977',\n",
      "       '1978', '1979', '1980', '1981', '1982', '1983', '1984', '1985', '1986',\n",
      "       '1987', '1988', '1989', '1990', '1991', '1992', '1993', '1994', '1995',\n",
      "       '1996', '1997', '1998', '1999', '2000', '2001', '2002', '2003', '2004',\n",
      "       '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013',\n",
      "       '2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022',\n",
      "       '2023', '2024'],\n",
      "      dtype='object')\n",
      "sr Columns:\n",
      " Index(['Country Name', 'Country Code', 'Indicator Name', 'Indicator Code',\n",
      "       '1960', '1961', '1962', '1963', '1964', '1965', '1966', '1967', '1968',\n",
      "       '1969', '1970', '1971', '1972', '1973', '1974', '1975', '1976', '1977',\n",
      "       '1978', '1979', '1980', '1981', '1982', '1983', '1984', '1985', '1986',\n",
      "       '1987', '1988', '1989', '1990', '1991', '1992', '1993', '1994', '1995',\n",
      "       '1996', '1997', '1998', '1999', '2000', '2001', '2002', '2003', '2004',\n",
      "       '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013',\n",
      "       '2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022',\n",
      "       '2023', '2024'],\n",
      "      dtype='object')\n",
      "su Columns:\n",
      " Index(['Country Name', 'Country Code', 'Indicator Name', 'Indicator Code',\n",
      "       '1960', '1961', '1962', '1963', '1964', '1965', '1966', '1967', '1968',\n",
      "       '1969', '1970', '1971', '1972', '1973', '1974', '1975', '1976', '1977',\n",
      "       '1978', '1979', '1980', '1981', '1982', '1983', '1984', '1985', '1986',\n",
      "       '1987', '1988', '1989', '1990', '1991', '1992', '1993', '1994', '1995',\n",
      "       '1996', '1997', '1998', '1999', '2000', '2001', '2002', '2003', '2004',\n",
      "       '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013',\n",
      "       '2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022',\n",
      "       '2023', '2024'],\n",
      "      dtype='object')\n",
      "pop Columns:\n",
      " Index(['Country Name', 'Country Code', 'Indicator Name', 'Indicator Code',\n",
      "       '1960', '1961', '1962', '1963', '1964', '1965', '1966', '1967', '1968',\n",
      "       '1969', '1970', '1971', '1972', '1973', '1974', '1975', '1976', '1977',\n",
      "       '1978', '1979', '1980', '1981', '1982', '1983', '1984', '1985', '1986',\n",
      "       '1987', '1988', '1989', '1990', '1991', '1992', '1993', '1994', '1995',\n",
      "       '1996', '1997', '1998', '1999', '2000', '2001', '2002', '2003', '2004',\n",
      "       '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013',\n",
      "       '2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022',\n",
      "       '2023', '2024'],\n",
      "      dtype='object')\n",
      "ren Columns:\n",
      " Index(['Country Name', 'Country Code', 'Indicator Name', 'Indicator Code',\n",
      "       '1960', '1961', '1962', '1963', '1964', '1965', '1966', '1967', '1968',\n",
      "       '1969', '1970', '1971', '1972', '1973', '1974', '1975', '1976', '1977',\n",
      "       '1978', '1979', '1980', '1981', '1982', '1983', '1984', '1985', '1986',\n",
      "       '1987', '1988', '1989', '1990', '1991', '1992', '1993', '1994', '1995',\n",
      "       '1996', '1997', '1998', '1999', '2000', '2001', '2002', '2003', '2004',\n",
      "       '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013',\n",
      "       '2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022',\n",
      "       '2023', '2024'],\n",
      "      dtype='object')\n",
      "gem Columns:\n",
      " Index(['Country Name', 'Country Code', 'Indicator Name', 'Indicator Code',\n",
      "       '1960', '1961', '1962', '1963', '1964', '1965', '1966', '1967', '1968',\n",
      "       '1969', '1970', '1971', '1972', '1973', '1974', '1975', '1976', '1977',\n",
      "       '1978', '1979', '1980', '1981', '1982', '1983', '1984', '1985', '1986',\n",
      "       '1987', '1988', '1989', '1990', '1991', '1992', '1993', '1994', '1995',\n",
      "       '1996', '1997', '1998', '1999', '2000', '2001', '2002', '2003', '2004',\n",
      "       '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013',\n",
      "       '2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022',\n",
      "       '2023', '2024'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"che Columns:\\n\", df_che.columns)\n",
    "print(\"wr Columns:\\n\", df_wr.columns)\n",
    "print(\"wu Columns:\\n\", df_wu.columns)\n",
    "print(\"sr Columns:\\n\", df_sr.columns)\n",
    "print(\"su Columns:\\n\", df_su.columns)\n",
    "print(\"pop Columns:\\n\", df_pop.columns)\n",
    "print(\"ren Columns:\\n\", df_ren.columns)\n",
    "print(\"gem Columns:\\n\", df_gem.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "770332d5-c32f-4341-a233-a9e469f8dca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all unique countries of the datasets\n",
    "df_che['Country Name'].unique();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85dede9-d7ce-418a-befc-eb1f12f0d42a",
   "metadata": {},
   "source": [
    "# Handling Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5333ac-9bc1-49dd-98b2-6892faf9f698",
   "metadata": {},
   "source": [
    "We will focus our analysis on the 2010s, that is, 2010–2019, as more recent data are likely to be of higher quality, with fewer outliers and errors. The years 2021–2024 contain many missing values, as the World Bank relies on countries to report data, and the most recent years are often incomplete or provisional. Data collection, validation, and submission take time, so the latest years may not yet be fully reported. Therefore, the 2010s appear to be the most suitable decade for examination.\n",
    "\n",
    "The final datasets will include data from 2008 to 2019 (12 years). We extend the range beyond 10 years to allow the calculation of a 10-year rolling average for all indicators, providing 1–2 extra years for yearly comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57bbbb5e-5dbc-4d5b-a2fa-5c8c4231c409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of DataFrames for automations\n",
    "all_dfs = [df_che, df_wr, df_wu, df_sr, df_su, df_gem, df_pop, df_ren]\n",
    "\n",
    "# Call the function, it returns all 8 DataFrames with NaNs directly\n",
    "df_che_nans, df_wr_nans, df_wu_nans, df_sr_nans, df_su_nans, df_gem_nans, df_pop_nans, df_ren_nans = custom_functions.calculate_nans_fixed_variables(all_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "682b7e6c-0e05-475f-87a9-e4b3ac211622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run it to see how our function behaves\n",
    "df_gem_nans;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40f15b2-f6f8-4aa8-ac6a-c5849c6b09b0",
   "metadata": {},
   "source": [
    "## Drop Unwanted Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "27ea33ef-400a-4c4d-a223-eb6174b08092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns (years) to be dropped from the DataFrames\n",
    "cols_to_drop = ['1960', '1961', '1962', '1963', '1964', '1965', '1966', '1967', '1968',\n",
    "       '1969', '1970', '1971', '1972', '1973', '1974', '1975', '1976', '1977',\n",
    "       '1978', '1979', '1980', '1981', '1982', '1983', '1984', '1985', '1986',\n",
    "       '1987', '1988', '1989', '1990', '1991', '1992', '1993', '1994', '1995',\n",
    "       '1996', '1997', '1998', '1999', '2000', '2001', '2002', '2003', '2004',\n",
    "       '2005', '2006', '2007', '2020', '2021', '2022', '2023', '2024']\n",
    "\n",
    "dfs_tuple = ()  # Initialize an empty tuple to store cleaned DataFrames\n",
    "\n",
    "# Iterate through all original DataFrames\n",
    "for df in all_dfs:\n",
    "    df_cleaned = df.drop(columns=cols_to_drop)  # Drop the specified year columns\n",
    "    dfs_tuple += (df_cleaned,)  # Add the cleaned DataFrame to the tuple\n",
    "\n",
    "# Unpack the tuple into separate variables for each cleaned DataFrame\n",
    "df_che2, df_wr2, df_wu2, df_sr2, df_su2, df_gem2, df_pop2, df_ren2 = dfs_tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a278cc3-c1dd-4f66-bec2-edca3b1e31af",
   "metadata": {},
   "source": [
    "## Fix the dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b457d937-fc87-4c38-9666-25222006e944",
   "metadata": {},
   "source": [
    "The errors='coerce' argument in pd.to_numeric() is very useful because it converts any invalid or non-numeric values to NaN. If all values in a column are converted to NaN, it indicates that the original data contains formatting issues or unexpected characters. This signals the need for preprocessing the strings — such as stripping whitespace, replacing commas with dots, or removing non-numeric symbols to ensure that the conversion to numeric values produces valid floats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c83631ad-8fed-4464-9b8a-c9d1265dc022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of year columns to include in the numeric conversion\n",
    "years_included = ['2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019']\n",
    "\n",
    "# List of cleaned DataFrames after dropping columns (version 2)\n",
    "all_dfs2 = [df_che2, df_wr2, df_wu2, df_sr2, df_su2, df_gem2, df_pop2, df_ren2]\n",
    "\n",
    "dfs_tuple = ()  # Initialize an empty tuple to store cleaned DataFrames\n",
    "\n",
    "# Iterate through all DataFrames and clean year columns\n",
    "for df in all_dfs2:\n",
    "    df_cleaned = df.copy()  # Work on a copy to preserve original\n",
    "    for year in years_included:\n",
    "        if year in df_cleaned.columns:\n",
    "            df_cleaned[year] = df_cleaned[year].astype(str).str.strip()  # Ensure string & remove spaces\n",
    "            df_cleaned[year] = df_cleaned[year].str.replace(',', '.')    # Replace comma with dot\n",
    "            df_cleaned[year] = df_cleaned[year].str.replace('%', '')     # Remove percent sign\n",
    "            df_cleaned[year] = pd.to_numeric(df_cleaned[year], errors='coerce')  # Convert to float\n",
    "    dfs_tuple += (df_cleaned,)  # Add cleaned DataFrame to the tuple\n",
    "\n",
    "# Unpack the tuple into separate variables for version 3\n",
    "df_che3, df_wr3, df_wu3, df_sr3, df_su3, df_gem3, df_pop3, df_ren3 = dfs_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "629acb12-acc2-4b0f-a0e4-c49500b639db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 266 entries, 0 to 265\n",
      "Data columns (total 16 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Country Name    266 non-null    object \n",
      " 1   Country Code    266 non-null    object \n",
      " 2   Indicator Name  266 non-null    object \n",
      " 3   Indicator Code  266 non-null    object \n",
      " 4   2008            235 non-null    float64\n",
      " 5   2009            235 non-null    float64\n",
      " 6   2010            236 non-null    float64\n",
      " 7   2011            237 non-null    float64\n",
      " 8   2012            237 non-null    float64\n",
      " 9   2013            238 non-null    float64\n",
      " 10  2014            238 non-null    float64\n",
      " 11  2015            238 non-null    float64\n",
      " 12  2016            238 non-null    float64\n",
      " 13  2017            239 non-null    float64\n",
      " 14  2018            240 non-null    float64\n",
      " 15  2019            240 non-null    float64\n",
      "dtypes: float64(12), object(4)\n",
      "memory usage: 33.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df_che3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c5f9a8-02d8-44e3-a078-991fd39d9b52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
