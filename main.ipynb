{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad1186e0-ccd5-4399-85ea-9363aa0764a1",
   "metadata": {},
   "source": [
    "# Introduction to Big Data Project - Main Python File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16d97d2c-6d10-48d4-8b3e-881708699f14",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Adespotos\\\\anaconda3\\\\envs\\\\bigdata_env\\\\python.exe'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that jupyter lab points to your project's environment directory\n",
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69be70bf-1b04-43dc-a384-fa54dec40ea1",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe5b17b7-1263-432d-97a7-77d354fe98d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # Numerical computing library\n",
    "import pandas as pd  # Data handling\n",
    "import matplotlib.pyplot as plt  # Plotting library\n",
    "import seaborn as sns  # An updated matplotlib (for better visualizations)\n",
    "import pymysql  # MySQL database connector for Python\n",
    "import chardet  # Library for automatic character encoding detection\n",
    "import re  # Regular expressions for string manipulation and pattern matching\n",
    "\n",
    "import custom_functions  # Custom functions for this project (e.g., CSV cleaning, encoding detection)\n",
    "\n",
    "pd.options.display.max_columns = 100  # Display all columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c6ff14-85b8-467d-b7fe-40fbfb144309",
   "metadata": {},
   "source": [
    "# DATA HARVESTING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef6adff-4d96-42e1-8c4e-e649c40c557b",
   "metadata": {},
   "source": [
    "# Read Datasets to DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d9a10a-ea74-40a6-b5e9-f7d211695f85",
   "metadata": {},
   "source": [
    "A detailed exploration of the CSV files is necessary to ensure they can be read correctly into DataFrames.\n",
    "\n",
    "We selected five health indicators and three environmental indicators. Some of these files are too complex to be read directly into DataFrames. The complexity became apparent when we realized that pandas.read_csv() could not handle the files properly, producing unreliable results.\n",
    "\n",
    "Rather than choosing easier files, we took this as an opportunity to develop a step-by-step solution and learn as much as possible from the process. The Pythonic approach we followed includes the steps below:\n",
    "\n",
    "1. Ensure the correct file encoding.\n",
    "2. Fetch the CSV files into Python’s runtime (without using pandas, since it could not read the files correctly).\n",
    "3. Explore the fetched CSV content to identify the issues.\n",
    "4. Write scripts to address one problem at a time, progressing toward the final solution.\n",
    "\n",
    "The indicators that required this special treatment were **\"Population, total\"** and **\"Renewable energy consumption (% of total final energy consumption)\"**. For this reason, we separated these two files from the rest, assigning them the notation 2, while the remaining files use the notation 1.\n",
    "\n",
    "To handle the process described above, we also created three custom functions for reading and cleaning the CSV files. We also included docstrings in our functions to improve their readability and understanding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36e5099-9da5-48ab-9e0a-27dbca7dbcf8",
   "metadata": {},
   "source": [
    "Therefore, as the first preprocessing step, we create the lists with file paths and data abbreviations. The mechanics are simple: the first element of filepaths_1 corresponds to the first element of abbreviations_1. The same applies to filepaths_2 and abbreviations_2. So, the custom creation order of the list elements matters. These lists make automation easier and help map each file to its abbreviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "756ef0e9-dd7e-4e16-8a3e-533ad1582d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths for notation 1 ('che', 'wr', 'wu', 'sr', 'su', 'gem')\n",
    "filepaths_1 = ['UPDATED CSV DATA - Intro to Big Data/Current health expenditure (% of GDP).csv',\n",
    "               'UPDATED CSV DATA - Intro to Big Data/People using at least basic drinking water services, rural (% of rural population).csv',\n",
    "               'UPDATED CSV DATA - Intro to Big Data/People using at least basic drinking water services, urban (% of urban population).csv',\n",
    "               'UPDATED CSV DATA - Intro to Big Data/People using safely managed sanitation services, rural (% of rural population).csv',\n",
    "               'UPDATED CSV DATA - Intro to Big Data/People using safely managed sanitation services, urban (% of urban population).csv',\n",
    "               'UPDATED CSV DATA - Intro to Big Data/Total greenhouse gas emissions including LULUCF (Mt CO2e).csv']\n",
    "\n",
    "# File paths for notation 2 ('pop', 'ren')\n",
    "filepaths_2 = ['UPDATED CSV DATA - Intro to Big Data/Population, total.csv',\n",
    "               'UPDATED CSV DATA - Intro to Big Data/Renewable energy consumption (% of total final energy consumption).csv']\n",
    "\n",
    "# Abbreviations for easy mapping: notation 1\n",
    "abbreviations_1 = ['che', 'wr', 'wu', 'sr', 'su', 'gem']\n",
    "\n",
    "# Abbreviations for easy mapping: notation 2\n",
    "abbreviations_2 = ['pop', 'ren']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e915cf-952a-4e18-b87e-755c7c1a4ac0",
   "metadata": {},
   "source": [
    "### Step 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41afcad-98f7-452d-a0d1-bbc84f862b9d",
   "metadata": {},
   "source": [
    "We use a function, leveraging chardet library's capabilities, to detect the file encoding, ensuring that no encoding issues occur when opening the CSV files in Python, which could otherwise disrupt our approach. We automated the process by iterating simultaneously over the abbreviations and filepaths lists. This type of iteration ensures that when Python processes element 0 of abbreviations, it also processes element 0 of filepaths, so each abbreviation corresponds to the correct file path."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0266c6d-5561-4634-b19b-52b4d2d245ef",
   "metadata": {},
   "source": [
    "**Notation 1 Files:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd70997e-ec74-451c-89e1-544862a20d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the files' encodings: \n",
      " {'che': 'UTF-8-SIG', 'wr': 'UTF-8-SIG', 'wu': 'UTF-8-SIG', 'sr': 'UTF-8-SIG', 'su': 'UTF-8-SIG', 'gem': 'UTF-8-SIG'}\n"
     ]
    }
   ],
   "source": [
    "# Dictionary to store detected encodings for each CSV file\n",
    "encodings_1 = {}\n",
    "\n",
    "# Iterate through abbreviations and filepaths together, detect encoding for each file\n",
    "for abbreviation, filepath in zip(abbreviations_1, filepaths_1):\n",
    "    encodings_1[abbreviation] = custom_functions.detect_encoding(filepath)\n",
    "\n",
    "# Print the results to verify encodings\n",
    "print(\"Here are the files' encodings: \\n\", encodings_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4210b0-b85b-4050-9f49-378331d30bb7",
   "metadata": {},
   "source": [
    "**Notation 2 Files:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42858863-c5ab-497b-a4f1-3214a528fb9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the files' encodings: \n",
      " {'pop': 'UTF-8-SIG', 'ren': 'UTF-8-SIG'}\n"
     ]
    }
   ],
   "source": [
    "# Dictionary to store detected encodings for each CSV file\n",
    "encodings_2 = {}\n",
    "\n",
    "# Iterate through abbreviations and filepaths together, detect encoding for each file\n",
    "for abbreviation, filepath in zip(abbreviations_2, filepaths_2):\n",
    "    encodings_2[abbreviation] = custom_functions.detect_encoding(filepath)\n",
    "\n",
    "# Print the results to verify encodings\n",
    "print(\"Here are the files' encodings: \\n\", encodings_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535a1f98-0434-48c3-8b7c-09f1eaeb0292",
   "metadata": {},
   "source": [
    "At this point, all encodings are safely stored as values in a dictionary. Things seem simple because the encodings are currently the same. However, if they ever differ, each encoding can be accessed using the corresponding dictionary key. Even though the situation looks straightforward now, we follow a dynamic approach and retrieve the encodings through the dictionary keys instead of writing the encoding manually for each file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb99f19f-9cd0-485d-9306-0dbe091f7b75",
   "metadata": {},
   "source": [
    "### Step 2 & 3:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2204ab-eebd-4557-a313-197e83b6c804",
   "metadata": {},
   "source": [
    "Since Pandas cannot handle reading these CSV files directly, we can use standard Python to load portions of a CSV file into memory. We can automate this process as before by iterating through both the filepaths and abbreviations lists and using a custom function that returns a selected line from each CSV file. We also use the repr() function, which is very helpful in situations like this, since the print() function often alters the displayed content. It is important to load the original CSV lines into memory without any changes to correctly identify the necessary actions to clean the files so that Pandas can read them successfully."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6ad6b9-70e2-4d05-a789-2de7a7e2996b",
   "metadata": {},
   "source": [
    "**Notation 1 Files:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35485635-b998-4b91-903b-759bed311bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "che:\n",
      "'Country Name;Country Code;Indicator Name;Indicator Code;1960;1961;1962;1963;1964;1965;1966;1967;1968;1969;1970;1971;1972;1973;1974;1975;1976;1977;1978;1979;1980;1981;1982;1983;1984;1985;1986;1987;1988;1989;1990;1991;1992;1993;1994;1995;1996;1997;1998;1999;2000;2001;2002;2003;2004;2005;2006;2007;2008;2009;2010;2011;2012;2013;2014;2015;2016;2017;2018;2019;2020;2021;2022;2023;2024\\n'\n",
      "wr:\n",
      "'Country Name;Country Code;Indicator Name;Indicator Code;1960;1961;1962;1963;1964;1965;1966;1967;1968;1969;1970;1971;1972;1973;1974;1975;1976;1977;1978;1979;1980;1981;1982;1983;1984;1985;1986;1987;1988;1989;1990;1991;1992;1993;1994;1995;1996;1997;1998;1999;2000;2001;2002;2003;2004;2005;2006;2007;2008;2009;2010;2011;2012;2013;2014;2015;2016;2017;2018;2019;2020;2021;2022;2023;2024\\n'\n",
      "wu:\n",
      "'Country Name;Country Code;Indicator Name;Indicator Code;1960;1961;1962;1963;1964;1965;1966;1967;1968;1969;1970;1971;1972;1973;1974;1975;1976;1977;1978;1979;1980;1981;1982;1983;1984;1985;1986;1987;1988;1989;1990;1991;1992;1993;1994;1995;1996;1997;1998;1999;2000;2001;2002;2003;2004;2005;2006;2007;2008;2009;2010;2011;2012;2013;2014;2015;2016;2017;2018;2019;2020;2021;2022;2023;2024\\n'\n",
      "sr:\n",
      "'Country Name;Country Code;Indicator Name;Indicator Code;1960;1961;1962;1963;1964;1965;1966;1967;1968;1969;1970;1971;1972;1973;1974;1975;1976;1977;1978;1979;1980;1981;1982;1983;1984;1985;1986;1987;1988;1989;1990;1991;1992;1993;1994;1995;1996;1997;1998;1999;2000;2001;2002;2003;2004;2005;2006;2007;2008;2009;2010;2011;2012;2013;2014;2015;2016;2017;2018;2019;2020;2021;2022;2023;2024\\n'\n",
      "su:\n",
      "'Country Name;Country Code;Indicator Name;Indicator Code;1960;1961;1962;1963;1964;1965;1966;1967;1968;1969;1970;1971;1972;1973;1974;1975;1976;1977;1978;1979;1980;1981;1982;1983;1984;1985;1986;1987;1988;1989;1990;1991;1992;1993;1994;1995;1996;1997;1998;1999;2000;2001;2002;2003;2004;2005;2006;2007;2008;2009;2010;2011;2012;2013;2014;2015;2016;2017;2018;2019;2020;2021;2022;2023;2024\\n'\n",
      "gem:\n",
      "'Country Name;Country Code;Indicator Name;Indicator Code;1960;1961;1962;1963;1964;1965;1966;1967;1968;1969;1970;1971;1972;1973;1974;1975;1976;1977;1978;1979;1980;1981;1982;1983;1984;1985;1986;1987;1988;1989;1990;1991;1992;1993;1994;1995;1996;1997;1998;1999;2000;2001;2002;2003;2004;2005;2006;2007;2008;2009;2010;2011;2012;2013;2014;2015;2016;2017;2018;2019;2020;2021;2022;2023;2024\\n'\n"
     ]
    }
   ],
   "source": [
    "# Iterate through abbreviations and filepaths together, print a CSV line for each file\n",
    "for abbreviation, filepath in zip(abbreviations_1, filepaths_1):\n",
    "    csv_part = custom_functions.explore_csv(filepath=filepath, encoding=encodings_1[abbreviation], line_number=3)\n",
    "    print(abbreviation + \":\")\n",
    "    print(repr(csv_part))  # repr() displays the string exactly as it is, unlike print() which might ruin special characters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ffcc3f-b9d5-4b7c-9338-1e70f8977399",
   "metadata": {},
   "source": [
    "**Notation 2 Files:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e851655b-a918-41c8-8b05-7aee8799b54e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pop:\n",
      "'\"Country Name,\"\"Country Code\"\",\"\"Indicator Name\"\",\"\"Indicator Code\"\",\"\"1960\"\",\"\"1961\"\",\"\"1962\"\",\"\"1963\"\",\"\"1964\"\",\"\"1965\"\",\"\"1966\"\",\"\"1967\"\",\"\"1968\"\",\"\"1969\"\",\"\"1970\"\",\"\"1971\"\",\"\"1972\"\",\"\"1973\"\",\"\"1974\"\",\"\"1975\"\",\"\"1976\"\",\"\"1977\"\",\"\"1978\"\",\"\"1979\"\",\"\"1980\"\",\"\"1981\"\",\"\"1982\"\",\"\"1983\"\",\"\"1984\"\",\"\"1985\"\",\"\"1986\"\",\"\"1987\"\",\"\"1988\"\",\"\"1989\"\",\"\"1990\"\",\"\"1991\"\",\"\"1992\"\",\"\"1993\"\",\"\"1994\"\",\"\"1995\"\",\"\"1996\"\",\"\"1997\"\",\"\"1998\"\",\"\"1999\"\",\"\"2000\"\",\"\"2001\"\",\"\"2002\"\",\"\"2003\"\",\"\"2004\"\",\"\"2005\"\",\"\"2006\"\",\"\"2007\"\",\"\"2008\"\",\"\"2009\"\",\"\"2010\"\",\"\"2011\"\",\"\"2012\"\",\"\"2013\"\",\"\"2014\"\",\"\"2015\"\",\"\"2016\"\",\"\"2017\"\",\"\"2018\"\",\"\"2019\"\",\"\"2020\"\",\"\"2021\"\",\"\"2022\"\",\"\"2023\"\",\"\"2024\"\",\"\\n'\n",
      "ren:\n",
      "'\"Country Name,\"\"Country Code\"\",\"\"Indicator Name\"\",\"\"Indicator Code\"\",\"\"1960\"\",\"\"1961\"\",\"\"1962\"\",\"\"1963\"\",\"\"1964\"\",\"\"1965\"\",\"\"1966\"\",\"\"1967\"\",\"\"1968\"\",\"\"1969\"\",\"\"1970\"\",\"\"1971\"\",\"\"1972\"\",\"\"1973\"\",\"\"1974\"\",\"\"1975\"\",\"\"1976\"\",\"\"1977\"\",\"\"1978\"\",\"\"1979\"\",\"\"1980\"\",\"\"1981\"\",\"\"1982\"\",\"\"1983\"\",\"\"1984\"\",\"\"1985\"\",\"\"1986\"\",\"\"1987\"\",\"\"1988\"\",\"\"1989\"\",\"\"1990\"\",\"\"1991\"\",\"\"1992\"\",\"\"1993\"\",\"\"1994\"\",\"\"1995\"\",\"\"1996\"\",\"\"1997\"\",\"\"1998\"\",\"\"1999\"\",\"\"2000\"\",\"\"2001\"\",\"\"2002\"\",\"\"2003\"\",\"\"2004\"\",\"\"2005\"\",\"\"2006\"\",\"\"2007\"\",\"\"2008\"\",\"\"2009\"\",\"\"2010\"\",\"\"2011\"\",\"\"2012\"\",\"\"2013\"\",\"\"2014\"\",\"\"2015\"\",\"\"2016\"\",\"\"2017\"\",\"\"2018\"\",\"\"2019\"\",\"\"2020\"\",\"\"2021\"\",\"\"2022\"\",\"\"2023\"\",\"\"2024\"\",\"\\n'\n"
     ]
    }
   ],
   "source": [
    "# Iterate through abbreviations and filepaths together, print a CSV line for each file\n",
    "for abbreviation, filepath in zip(abbreviations_2, filepaths_2):\n",
    "    csv_part = custom_functions.explore_csv(filepath=filepath, encoding=encodings_2[abbreviation], line_number=4)\n",
    "    print(abbreviation + \":\")\n",
    "    print(repr(csv_part))  # repr() displays the string exactly as it is, unlike print() which ruins special characters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95b9fb0-7fee-447f-8da8-8f59176e2b40",
   "metadata": {},
   "source": [
    "The above scripts, along with the custom function explore_csv, helped us identify the following:\n",
    "\n",
    "1. All notation 1 files start at line number 3, whereas notation 2 files start at line number 4. The preceding lines contain metadata at both cases.\n",
    "2. All notation 1 files use ';' as a separator, whereas notation 2 files use ','.\n",
    "3. Rows in every file end with a newline character '\\n'.\n",
    "4. There are empty strings that should be manually converted to NaN values. Otherwise, pandas cannot recognize them as missing data.\n",
    "5. Apart from the delimiter and the newline character at the end, the notation 1 files are clean, while notation 2 files include the following extra issues:  \n",
    "    a. Each row ends with a comma followed by a quote, before the newline character: ',\"\\n'.  \n",
    "    b. Quotes included in the data.  \n",
    "    c. In 'pop', there is an extra comma in the column name 'Population, total', which causes pandas to treat 'Population' and 'total' as separate columns, even though they belong to the same column.  \n",
    "    d. Each list element represents a row of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722778e4-8c07-4fcb-ad76-08006ee5f18e",
   "metadata": {},
   "source": [
    "Although the identification appears to be correct and effective, the order of execution of the above instructions is important. For instance, removing all quotes before applying rstrip() can lead to unreliable results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0114c1e2-3047-4251-80cd-dba76ed849f1",
   "metadata": {},
   "source": [
    "### Step 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e151ce7-7ac0-4c6f-bb0d-b06cb357bb34",
   "metadata": {},
   "source": [
    "We created a custom function to clean all files. The function is dynamic, meaning it can handle both notation 1 and notation 2 datasets. The only point that requires attention is that the function must accept different arguments depending on the file notation. As mentioned before, notation 2 files require special treatment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8544644-922a-4006-b5a9-4e13d1a5bd6c",
   "metadata": {},
   "source": [
    "We adopted a new approach by creating a third list that maps to the other two lists introduced earlier. This third list contains the names of the DataFrames."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaba3b22-6fbe-4608-9f5e-ac963f5af21b",
   "metadata": {},
   "source": [
    "**Reading Notation 1 Files to DataFrames:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cc2b8bb-45f9-4a32-9176-21b05e934b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of the DataFrames for notation 1\n",
    "dfnames_1 = ['df_che', 'df_wr', 'df_wu', 'df_sr', 'df_su', 'df_gem']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bd9df30-0eb0-4054-bc0e-ec1534904844",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict_1 = {}  # Initialize an empty dictionary to store the DataFrames\n",
    "\n",
    "# Iterate through the three lists simultaneously.\n",
    "# This works because the lists were created with the correct mapping order.\n",
    "for df_name, abbreviation, filepath in zip(dfnames_1, abbreviations_1, filepaths_1):\n",
    "    # Use the DataFrame name string as the key in the dictionary\n",
    "    df_dict_1[df_name] = custom_functions.clean_csv(\n",
    "        filepath=filepath,  # Path to the CSV file\n",
    "        encoding=encodings_1[abbreviation],  # Retrieve encoding based on abbreviation\n",
    "        separator=';',   # Set the column delimiter\n",
    "        trail1='\\n',  # First trailing character to remove\n",
    "        trail2=None,  # Second trailing character to remove (optional)\n",
    "        trail3=None,  # Third trailing character to remove (optional)\n",
    "        to_be_replaced='\"',  # Characters to replace (quotes in this case)\n",
    "        start_row=3  # Row index corresponding to column headers\n",
    "    )\n",
    "\n",
    "# Extract the DataFrames from the dictionary and assign to variables\n",
    "df_che = df_dict_1['df_che']\n",
    "df_wr  = df_dict_1['df_wr']\n",
    "df_wu  = df_dict_1['df_wu']\n",
    "df_sr  = df_dict_1['df_sr']\n",
    "df_su  = df_dict_1['df_su']\n",
    "df_gem = df_dict_1['df_gem']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d1cdfc-af08-4a00-9f51-65f87c09794a",
   "metadata": {},
   "source": [
    "**Reading Notation 2 Files to DataFrames:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a382c21c-20f2-464c-b7bf-72e71b0f1db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of the DataFrames for notation 2\n",
    "dfnames_2 = ['df_pop', 'df_ren']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "adc6b8bf-bcf6-47db-83f8-120b75fa96cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict_2 = {}\n",
    "\n",
    "for df_name, abbreviation, filepath in zip(dfnames_2, abbreviations_2, filepaths_2):\n",
    "    df_dict_2[df_name] = custom_functions.clean_csv(\n",
    "        filepath=filepath,\n",
    "        encoding=encodings_2[abbreviation],\n",
    "        separator=',',\n",
    "        trail1='\\n',\n",
    "        trail2='\"',\n",
    "        trail3=',',\n",
    "        to_be_replaced='\"',\n",
    "        start_row=4\n",
    "    )\n",
    "    \n",
    "df_pop = df_dict_2['df_pop']\n",
    "df_ren = df_dict_2['df_ren']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37d2b6f-4d8c-4978-a162-a6177d5935cd",
   "metadata": {},
   "source": [
    "Below is a list that includes all DataFrames. This is a convenient way to iterate through them later, automate some processes, and keep the code clean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a96f5d95-4bf7-4200-9201-bbf8eec138d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of DataFrames for automations\n",
    "all_dfs = [df_che, df_wr, df_wu, df_sr, df_su, df_gem, df_pop, df_ren]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232370bf-ce5d-49a8-8202-99be6ae051a3",
   "metadata": {},
   "source": [
    "# Quick Exploration on Data Integrity & Observations "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6de22d-8ad0-4b6c-aee7-5f6dabbae451",
   "metadata": {},
   "source": [
    "The results appear reliable, as all DataFrames have the same shape and identical column names. A quick inspection suggests that our cleaning process has been effective. All indicators are related to countries, so the 266 rows represent countries and territories worldwide. The 193 sovereign countries are included, but the additional rows correspond to non-independent territories, overseas dependencies and entire regions, such as Puerto Rico, Hong Kong, Bermuda, Africa Eastern and Southern. Arab World etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932f34bd-0781-4dd8-954f-7c9d6348f2aa",
   "metadata": {},
   "source": [
    "The indicators’ data have been collected from 1960 to the present (2024). There are several reasons why 1960 is used as the starting year. By this time, most countries had rebuilt or established functioning statistical offices after World War II, enabling systematic and comparable data collection. Additionally, decolonization and the formation of new countries occurred primarily in the 1950s and 1960s. Many nations became independent around this period, so data prior to 1960 would often be incomplete, inconsistent, or recorded under colonial administrations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "804fd065-d860-4c3b-b19a-1700cf979906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "che: (266, 69)\n",
      "wr: (266, 69)\n",
      "wu: (266, 69)\n",
      "sr: (266, 69)\n",
      "su: (266, 69)\n",
      "pop: (266, 69)\n",
      "ren: (266, 69)\n",
      "gem: (266, 69)\n"
     ]
    }
   ],
   "source": [
    "print('che:', df_che.shape)\n",
    "print('wr:', df_wr.shape)\n",
    "print('wu:', df_wu.shape)\n",
    "print('sr:', df_sr.shape)\n",
    "print('su:', df_su.shape)\n",
    "print('pop:', df_pop.shape)\n",
    "print('ren:', df_ren.shape)\n",
    "print('gem:', df_gem.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8f361ce-26e1-4a0f-a214-6b65554dac2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "che Columns:\n",
      " Index(['Country Name', 'Country Code', 'Indicator Name', 'Indicator Code',\n",
      "       '1960', '1961', '1962', '1963', '1964', '1965', '1966', '1967', '1968',\n",
      "       '1969', '1970', '1971', '1972', '1973', '1974', '1975', '1976', '1977',\n",
      "       '1978', '1979', '1980', '1981', '1982', '1983', '1984', '1985', '1986',\n",
      "       '1987', '1988', '1989', '1990', '1991', '1992', '1993', '1994', '1995',\n",
      "       '1996', '1997', '1998', '1999', '2000', '2001', '2002', '2003', '2004',\n",
      "       '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013',\n",
      "       '2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022',\n",
      "       '2023', '2024'],\n",
      "      dtype='object')\n",
      "wr Columns:\n",
      " Index(['Country Name', 'Country Code', 'Indicator Name', 'Indicator Code',\n",
      "       '1960', '1961', '1962', '1963', '1964', '1965', '1966', '1967', '1968',\n",
      "       '1969', '1970', '1971', '1972', '1973', '1974', '1975', '1976', '1977',\n",
      "       '1978', '1979', '1980', '1981', '1982', '1983', '1984', '1985', '1986',\n",
      "       '1987', '1988', '1989', '1990', '1991', '1992', '1993', '1994', '1995',\n",
      "       '1996', '1997', '1998', '1999', '2000', '2001', '2002', '2003', '2004',\n",
      "       '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013',\n",
      "       '2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022',\n",
      "       '2023', '2024'],\n",
      "      dtype='object')\n",
      "wu Columns:\n",
      " Index(['Country Name', 'Country Code', 'Indicator Name', 'Indicator Code',\n",
      "       '1960', '1961', '1962', '1963', '1964', '1965', '1966', '1967', '1968',\n",
      "       '1969', '1970', '1971', '1972', '1973', '1974', '1975', '1976', '1977',\n",
      "       '1978', '1979', '1980', '1981', '1982', '1983', '1984', '1985', '1986',\n",
      "       '1987', '1988', '1989', '1990', '1991', '1992', '1993', '1994', '1995',\n",
      "       '1996', '1997', '1998', '1999', '2000', '2001', '2002', '2003', '2004',\n",
      "       '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013',\n",
      "       '2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022',\n",
      "       '2023', '2024'],\n",
      "      dtype='object')\n",
      "sr Columns:\n",
      " Index(['Country Name', 'Country Code', 'Indicator Name', 'Indicator Code',\n",
      "       '1960', '1961', '1962', '1963', '1964', '1965', '1966', '1967', '1968',\n",
      "       '1969', '1970', '1971', '1972', '1973', '1974', '1975', '1976', '1977',\n",
      "       '1978', '1979', '1980', '1981', '1982', '1983', '1984', '1985', '1986',\n",
      "       '1987', '1988', '1989', '1990', '1991', '1992', '1993', '1994', '1995',\n",
      "       '1996', '1997', '1998', '1999', '2000', '2001', '2002', '2003', '2004',\n",
      "       '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013',\n",
      "       '2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022',\n",
      "       '2023', '2024'],\n",
      "      dtype='object')\n",
      "su Columns:\n",
      " Index(['Country Name', 'Country Code', 'Indicator Name', 'Indicator Code',\n",
      "       '1960', '1961', '1962', '1963', '1964', '1965', '1966', '1967', '1968',\n",
      "       '1969', '1970', '1971', '1972', '1973', '1974', '1975', '1976', '1977',\n",
      "       '1978', '1979', '1980', '1981', '1982', '1983', '1984', '1985', '1986',\n",
      "       '1987', '1988', '1989', '1990', '1991', '1992', '1993', '1994', '1995',\n",
      "       '1996', '1997', '1998', '1999', '2000', '2001', '2002', '2003', '2004',\n",
      "       '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013',\n",
      "       '2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022',\n",
      "       '2023', '2024'],\n",
      "      dtype='object')\n",
      "pop Columns:\n",
      " Index(['Country Name', 'Country Code', 'Indicator Name', 'Indicator Code',\n",
      "       '1960', '1961', '1962', '1963', '1964', '1965', '1966', '1967', '1968',\n",
      "       '1969', '1970', '1971', '1972', '1973', '1974', '1975', '1976', '1977',\n",
      "       '1978', '1979', '1980', '1981', '1982', '1983', '1984', '1985', '1986',\n",
      "       '1987', '1988', '1989', '1990', '1991', '1992', '1993', '1994', '1995',\n",
      "       '1996', '1997', '1998', '1999', '2000', '2001', '2002', '2003', '2004',\n",
      "       '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013',\n",
      "       '2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022',\n",
      "       '2023', '2024'],\n",
      "      dtype='object')\n",
      "ren Columns:\n",
      " Index(['Country Name', 'Country Code', 'Indicator Name', 'Indicator Code',\n",
      "       '1960', '1961', '1962', '1963', '1964', '1965', '1966', '1967', '1968',\n",
      "       '1969', '1970', '1971', '1972', '1973', '1974', '1975', '1976', '1977',\n",
      "       '1978', '1979', '1980', '1981', '1982', '1983', '1984', '1985', '1986',\n",
      "       '1987', '1988', '1989', '1990', '1991', '1992', '1993', '1994', '1995',\n",
      "       '1996', '1997', '1998', '1999', '2000', '2001', '2002', '2003', '2004',\n",
      "       '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013',\n",
      "       '2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022',\n",
      "       '2023', '2024'],\n",
      "      dtype='object')\n",
      "gem Columns:\n",
      " Index(['Country Name', 'Country Code', 'Indicator Name', 'Indicator Code',\n",
      "       '1960', '1961', '1962', '1963', '1964', '1965', '1966', '1967', '1968',\n",
      "       '1969', '1970', '1971', '1972', '1973', '1974', '1975', '1976', '1977',\n",
      "       '1978', '1979', '1980', '1981', '1982', '1983', '1984', '1985', '1986',\n",
      "       '1987', '1988', '1989', '1990', '1991', '1992', '1993', '1994', '1995',\n",
      "       '1996', '1997', '1998', '1999', '2000', '2001', '2002', '2003', '2004',\n",
      "       '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013',\n",
      "       '2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022',\n",
      "       '2023', '2024'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"che Columns:\\n\", df_che.columns)\n",
    "print(\"wr Columns:\\n\", df_wr.columns)\n",
    "print(\"wu Columns:\\n\", df_wu.columns)\n",
    "print(\"sr Columns:\\n\", df_sr.columns)\n",
    "print(\"su Columns:\\n\", df_su.columns)\n",
    "print(\"pop Columns:\\n\", df_pop.columns)\n",
    "print(\"ren Columns:\\n\", df_ren.columns)\n",
    "print(\"gem Columns:\\n\", df_gem.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "770332d5-c32f-4341-a233-a9e469f8dca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all unique countries of the datasets\n",
    "df_che['Country Name'].unique();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85dede9-d7ce-418a-befc-eb1f12f0d42a",
   "metadata": {},
   "source": [
    "# Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57bbbb5e-5dbc-4d5b-a2fa-5c8c4231c409",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nans = []  # Empty list to host the DataFrames with NaNs\n",
    "for df in all_dfs:  # Iterate through DataFrames list\n",
    "    columns = df.columns  # Assign columns\n",
    "    data = df.isna().sum().values.reshape(1, 69)  # Calculate NaNs reshaping them\n",
    "    df = pd.DataFrame(data=data, columns=columns)  # Create the DataFrame with NaNs\n",
    "    df_nans.append(df)  # Add the DataFrame to the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "06cc4dca-3643-4bdd-b087-4d7eb9605475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually correct the names\n",
    "df_che_nans = df_nans[0]\n",
    "df_wr_nans = df_nans[1]\n",
    "df_wu_nans = df_nans[2]\n",
    "df_sr_nans = df_nans[3]\n",
    "df_su_nans = df_nans[4]\n",
    "df_gem_nans = df_nans[5]\n",
    "df_pop_nans = df_nans[6]\n",
    "df_ren_nans = df_nans[7]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856e737a-2155-40d6-9bd9-d12e8a9d83ed",
   "metadata": {},
   "source": [
    "Current health expenditure (% of GDP)\n",
    "For Current Health Expenditure (% of GDP), seeing all missing values until 2000, and then 232 out of 266 countries starting to report in 2000, is consistent with the history of international health data collection. Health expenditure tracking requires national health accounts (NHAs). Many countries did not have a formal NHA system until late 1990s–early 2000s. Developing countries, especially in Africa, Asia, and Latin America, started implementing NHAs only around 2000. Additionally, World Bank metadata confirms that systematic collection of health expenditure as % of GDP began in 2000 for most countries.\n",
    "People using at least basic drinking water services, rural (% of rural population)\n",
    "People using at least basic drinking water services, urban (% of urban population)\n",
    "People using safely managed sanitation services, rural (% of rural population)\n",
    "People using safely managed sanitation services, urban (% of urban population)\n",
    "Total greenhouse gas emissions including LULUCF (Mt CO2e)\n",
    "Population, total\n",
    "Renewable energy consumption (% of total final energy consumption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e6a4cf73-5ec8-4207-998a-558364a6ded2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country Name</th>\n",
       "      <th>Country Code</th>\n",
       "      <th>Indicator Name</th>\n",
       "      <th>Indicator Code</th>\n",
       "      <th>1960</th>\n",
       "      <th>1961</th>\n",
       "      <th>1962</th>\n",
       "      <th>1963</th>\n",
       "      <th>1964</th>\n",
       "      <th>1965</th>\n",
       "      <th>1966</th>\n",
       "      <th>1967</th>\n",
       "      <th>1968</th>\n",
       "      <th>1969</th>\n",
       "      <th>1970</th>\n",
       "      <th>1971</th>\n",
       "      <th>1972</th>\n",
       "      <th>1973</th>\n",
       "      <th>1974</th>\n",
       "      <th>1975</th>\n",
       "      <th>1976</th>\n",
       "      <th>1977</th>\n",
       "      <th>1978</th>\n",
       "      <th>1979</th>\n",
       "      <th>1980</th>\n",
       "      <th>1981</th>\n",
       "      <th>1982</th>\n",
       "      <th>1983</th>\n",
       "      <th>1984</th>\n",
       "      <th>1985</th>\n",
       "      <th>1986</th>\n",
       "      <th>1987</th>\n",
       "      <th>1988</th>\n",
       "      <th>1989</th>\n",
       "      <th>1990</th>\n",
       "      <th>1991</th>\n",
       "      <th>1992</th>\n",
       "      <th>1993</th>\n",
       "      <th>1994</th>\n",
       "      <th>1995</th>\n",
       "      <th>1996</th>\n",
       "      <th>1997</th>\n",
       "      <th>1998</th>\n",
       "      <th>1999</th>\n",
       "      <th>2000</th>\n",
       "      <th>2001</th>\n",
       "      <th>2002</th>\n",
       "      <th>2003</th>\n",
       "      <th>2004</th>\n",
       "      <th>2005</th>\n",
       "      <th>2006</th>\n",
       "      <th>2007</th>\n",
       "      <th>2008</th>\n",
       "      <th>2009</th>\n",
       "      <th>2010</th>\n",
       "      <th>2011</th>\n",
       "      <th>2012</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "      <th>2020</th>\n",
       "      <th>2021</th>\n",
       "      <th>2022</th>\n",
       "      <th>2023</th>\n",
       "      <th>2024</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>33</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "      <td>245</td>\n",
       "      <td>266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country Name  Country Code  Indicator Name  Indicator Code  1960  1961  \\\n",
       "0             0             0               0               0   266   266   \n",
       "\n",
       "   1962  1963  1964  1965  1966  1967  1968  1969  1970  1971  1972  1973  \\\n",
       "0   266   266   266   266   266   266   266   266   266   266   266   266   \n",
       "\n",
       "   1974  1975  1976  1977  1978  1979  1980  1981  1982  1983  1984  1985  \\\n",
       "0   266   266   266   266   266   266   266   266   266   266   266   266   \n",
       "\n",
       "   1986  1987  1988  1989  1990  1991  1992  1993  1994  1995  1996  1997  \\\n",
       "0   266   266   266   266   266   266   266   266   266   266   266   266   \n",
       "\n",
       "   1998  1999  2000  2001  2002  2003  2004  2005  2006  2007  2008  2009  \\\n",
       "0   266   266    34    34    33    31    31    31    31    31    31    31   \n",
       "\n",
       "   2010  2011  2012  2013  2014  2015  2016  2017  2018  2019  2020  2021  \\\n",
       "0    30    29    29    28    28    28    28    27    26    26    26    26   \n",
       "\n",
       "   2022  2023  2024  \n",
       "0    27   245   266  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_che_nans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6045facb-29c9-432b-a072-66c243bfe6d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country Name</th>\n",
       "      <th>Country Code</th>\n",
       "      <th>Indicator Name</th>\n",
       "      <th>Indicator Code</th>\n",
       "      <th>1960</th>\n",
       "      <th>1961</th>\n",
       "      <th>1962</th>\n",
       "      <th>1963</th>\n",
       "      <th>1964</th>\n",
       "      <th>1965</th>\n",
       "      <th>1966</th>\n",
       "      <th>1967</th>\n",
       "      <th>1968</th>\n",
       "      <th>1969</th>\n",
       "      <th>1970</th>\n",
       "      <th>1971</th>\n",
       "      <th>1972</th>\n",
       "      <th>1973</th>\n",
       "      <th>1974</th>\n",
       "      <th>1975</th>\n",
       "      <th>1976</th>\n",
       "      <th>1977</th>\n",
       "      <th>1978</th>\n",
       "      <th>1979</th>\n",
       "      <th>1980</th>\n",
       "      <th>1981</th>\n",
       "      <th>1982</th>\n",
       "      <th>1983</th>\n",
       "      <th>1984</th>\n",
       "      <th>1985</th>\n",
       "      <th>1986</th>\n",
       "      <th>1987</th>\n",
       "      <th>1988</th>\n",
       "      <th>1989</th>\n",
       "      <th>1990</th>\n",
       "      <th>1991</th>\n",
       "      <th>1992</th>\n",
       "      <th>1993</th>\n",
       "      <th>1994</th>\n",
       "      <th>1995</th>\n",
       "      <th>1996</th>\n",
       "      <th>1997</th>\n",
       "      <th>1998</th>\n",
       "      <th>1999</th>\n",
       "      <th>2000</th>\n",
       "      <th>2001</th>\n",
       "      <th>2002</th>\n",
       "      <th>2003</th>\n",
       "      <th>2004</th>\n",
       "      <th>2005</th>\n",
       "      <th>2006</th>\n",
       "      <th>2007</th>\n",
       "      <th>2008</th>\n",
       "      <th>2009</th>\n",
       "      <th>2010</th>\n",
       "      <th>2011</th>\n",
       "      <th>2012</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "      <th>2020</th>\n",
       "      <th>2021</th>\n",
       "      <th>2022</th>\n",
       "      <th>2023</th>\n",
       "      <th>2024</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>World</td>\n",
       "      <td>WLD</td>\n",
       "      <td>Total greenhouse gas emissions including LULUC...</td>\n",
       "      <td>EN.GHG.ALL.LU.MT.CE.AR5</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>31342,82431</td>\n",
       "      <td>31436,0547</td>\n",
       "      <td>31499,45781</td>\n",
       "      <td>31899,84709</td>\n",
       "      <td>32100,025</td>\n",
       "      <td>34075,93276</td>\n",
       "      <td>33610,33536</td>\n",
       "      <td>32984,55005</td>\n",
       "      <td>34335,38494</td>\n",
       "      <td>34679,15975</td>\n",
       "      <td>36704,4151</td>\n",
       "      <td>35413,74566</td>\n",
       "      <td>36771,07088</td>\n",
       "      <td>38590,53981</td>\n",
       "      <td>41125,84819</td>\n",
       "      <td>41077,2551</td>\n",
       "      <td>43139,24053</td>\n",
       "      <td>43331,66492</td>\n",
       "      <td>42831,4438</td>\n",
       "      <td>41836,71677</td>\n",
       "      <td>43924,12891</td>\n",
       "      <td>47535,57026</td>\n",
       "      <td>48432,30915</td>\n",
       "      <td>48204,66336</td>\n",
       "      <td>48999,1287</td>\n",
       "      <td>49218,82751</td>\n",
       "      <td>47875,50134</td>\n",
       "      <td>49119,04844</td>\n",
       "      <td>50984,951</td>\n",
       "      <td>51278,3474</td>\n",
       "      <td>48871,42231</td>\n",
       "      <td>51737,72293</td>\n",
       "      <td>51838,06473</td>\n",
       "      <td>54500,70669</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Country Name Country Code  \\\n",
       "259        World          WLD   \n",
       "\n",
       "                                        Indicator Name  \\\n",
       "259  Total greenhouse gas emissions including LULUC...   \n",
       "\n",
       "              Indicator Code  1960  1961  1962  1963  1964  1965  1966  1967  \\\n",
       "259  EN.GHG.ALL.LU.MT.CE.AR5  None  None  None  None  None  None  None  None   \n",
       "\n",
       "     1968  1969  1970  1971  1972  1973  1974  1975  1976  1977  1978  1979  \\\n",
       "259  None  None  None  None  None  None  None  None  None  None  None  None   \n",
       "\n",
       "     1980  1981  1982  1983  1984  1985  1986  1987  1988  1989         1990  \\\n",
       "259  None  None  None  None  None  None  None  None  None  None  31342,82431   \n",
       "\n",
       "           1991         1992         1993       1994         1995  \\\n",
       "259  31436,0547  31499,45781  31899,84709  32100,025  34075,93276   \n",
       "\n",
       "            1996         1997         1998         1999        2000  \\\n",
       "259  33610,33536  32984,55005  34335,38494  34679,15975  36704,4151   \n",
       "\n",
       "            2001         2002         2003         2004        2005  \\\n",
       "259  35413,74566  36771,07088  38590,53981  41125,84819  41077,2551   \n",
       "\n",
       "            2006         2007        2008         2009         2010  \\\n",
       "259  43139,24053  43331,66492  42831,4438  41836,71677  43924,12891   \n",
       "\n",
       "            2011         2012         2013        2014         2015  \\\n",
       "259  47535,57026  48432,30915  48204,66336  48999,1287  49218,82751   \n",
       "\n",
       "            2016         2017       2018        2019         2020  \\\n",
       "259  47875,50134  49119,04844  50984,951  51278,3474  48871,42231   \n",
       "\n",
       "            2021         2022         2023  2024  \n",
       "259  51737,72293  51838,06473  54500,70669  None  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gem[df_gem['1990'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3605fac9-1a71-47ad-8a11-4d51c602b44e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
